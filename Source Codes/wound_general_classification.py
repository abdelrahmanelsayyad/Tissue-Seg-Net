{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7200157,"sourceType":"datasetVersion","datasetId":4124555},{"sourceId":11831422,"sourceType":"datasetVersion","datasetId":7432806}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:09.183869Z\",\"iopub.execute_input\":\"2025-05-27T17:59:09.184282Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.491087Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:09.184261Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.490330Z\"}}\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\nfrom collections import Counter\nimport json\nimport logging\nfrom typing import Tuple, Dict, Any, List\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# FastAI imports\nfrom fastai.vision.all import *\nfrom fastai.callback.all import *\nfrom fastai.metrics import accuracy, error_rate\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.492217Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.492603Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.497235Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.492575Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.496435Z\"}}\n# Configuration\nDATASET_PATH = '/kaggle/input/wound-classification/Wound_dataset copy'\nOUTPUT_DIR = '/kaggle/working'\nSEED = 42\nIMG_SIZE = 224\nBATCH_SIZE = 16  # Reduced for better gradient updates\nEPOCHS = 25\nMIN_SAMPLES_PER_CLASS = 50  # Minimum samples after augmentation\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.498068Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.498326Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.541627Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.498306Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.540969Z\"}}\ndef set_seed(seed: int = 42) -> None:\n    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(SEED)\nPath(OUTPUT_DIR).mkdir(exist_ok=True, parents=True)\n\nprint(f\"Enhanced Configuration:\")\nprint(f\"- Dataset Path: {DATASET_PATH}\")\nprint(f\"- Output Directory: {OUTPUT_DIR}\")\nprint(f\"- Image Size: {IMG_SIZE}\")\nprint(f\"- Batch Size: {BATCH_SIZE}\")\nprint(f\"- Epochs: {EPOCHS}\")\nprint(f\"- Min Samples Per Class: {MIN_SAMPLES_PER_CLASS}\")\nprint(f\"- Random Seed: {SEED}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.543386Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.543574Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.550854Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.543558Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.550198Z\"}}\ndef load_and_explore_data(dataset_path: str) -> pd.DataFrame:\n    \"\"\"Load dataset and create DataFrame with exploratory data analysis.\"\"\"\n    logger.info(\"Loading and exploring dataset...\")\n    \n    dataset_path = Path(dataset_path)\n    if not dataset_path.exists():\n        raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n    \n    data = {'Path': [], 'Class': []}\n    \n    for class_dir in dataset_path.iterdir():\n        if class_dir.is_dir():\n            class_name = class_dir.name\n            image_files = list(class_dir.glob('*'))\n            \n            # Filter valid image extensions\n            valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n            image_files = [f for f in image_files if f.suffix.lower() in valid_extensions]\n            \n            for img_file in image_files:\n                relative_path = img_file.relative_to(dataset_path)\n                data['Path'].append(str(relative_path))\n                data['Class'].append(class_name)\n    \n    df = pd.DataFrame(data)\n    \n    if df.empty:\n        raise ValueError(\"No valid images found in the dataset\")\n    \n    # Log dataset statistics\n    logger.info(f\"Dataset loaded: {len(df)} images across {df['Class'].nunique()} classes\")\n    print(f\"\\nDataset Statistics:\")\n    print(f\"Total Images: {len(df)}\")\n    print(f\"Number of Classes: {df['Class'].nunique()}\")\n    print(f\"\\nClass Distribution:\")\n    class_counts = df['Class'].value_counts()\n    print(class_counts)\n    \n    # Check for class imbalance\n    imbalance_ratio = class_counts.max() / class_counts.min()\n    print(f\"\\n‚ö†Ô∏è Class Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n    \n    return df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.551636Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.552397Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.600163Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.552374Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.599500Z\"}}\ndef create_synthetic_samples(df: pd.DataFrame, dataset_path: str, target_samples: int = MIN_SAMPLES_PER_CLASS) -> pd.DataFrame:\n    \"\"\"Create synthetic samples using data augmentation for minority classes.\"\"\"\n    logger.info(\"Creating synthetic samples for minority classes...\")\n    \n    class_counts = df['Class'].value_counts()\n    print(f\"\\nOriginal class distribution:\")\n    print(class_counts)\n    \n    # Identify classes that need augmentation\n    classes_to_augment = class_counts[class_counts < target_samples].index.tolist()\n    \n    if not classes_to_augment:\n        print(\"No classes need augmentation.\")\n        return df\n    \n    print(f\"\\nClasses requiring augmentation: {classes_to_augment}\")\n    \n    # Enhanced augmentation transforms for synthetic data generation\n    heavy_aug_tfms = [\n        Rotate(max_deg=30, p=0.8),\n        Zoom(max_zoom=1.3, p=0.8),\n        Warp(magnitude=0.3, p=0.7),\n        Brightness(max_lighting=0.4, p=0.7),\n        Contrast(max_lighting=0.4, p=0.7),\n        Flip(p=0.5),\n        Dihedral(p=0.3),  # 8-way symmetry\n        Cutout(n_holes=2, length=20, p=0.5)\n    ]\n    \n    synthetic_data = []\n    \n    for class_name in classes_to_augment:\n        current_count = class_counts[class_name]\n        needed_samples = target_samples - current_count\n        \n        print(f\"Generating {needed_samples} synthetic samples for {class_name}\")\n        \n        # Get existing samples for this class\n        class_samples = df[df['Class'] == class_name]['Path'].tolist()\n        \n        # Generate synthetic samples\n        for i in range(needed_samples):\n            # Randomly select a source image\n            source_path = np.random.choice(class_samples)\n            \n            # Create synthetic filename\n            synthetic_path = f\"synthetic_{class_name}_{i:04d}.jpg\"\n            \n            synthetic_data.append({\n                'Path': synthetic_path,\n                'Class': class_name,\n                'is_synthetic': True,\n                'source_path': source_path\n            })\n    \n    # Create synthetic DataFrame\n    synthetic_df = pd.DataFrame(synthetic_data)\n    \n    # Add is_synthetic column to original data\n    df['is_synthetic'] = False\n    df['source_path'] = df['Path']\n    \n    # Combine original and synthetic data\n    balanced_df = pd.concat([df, synthetic_df], ignore_index=True)\n    \n    print(f\"\\nBalanced class distribution:\")\n    print(balanced_df['Class'].value_counts())\n        \n    print(f\"Total synthetic samples created: {len(synthetic_df)}\")\n    \n    return balanced_df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.600974Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.601404Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.627372Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.601381Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.626775Z\"}}\nclass SyntheticImageDataLoaders(ImageDataLoaders):\n    \"\"\"Custom DataLoaders that handles synthetic image generation on-the-fly.\"\"\"\n    \n    @classmethod\n    def from_df_with_synthetic(cls, df, path, fn_col='Path', label_col='Class', \n                             valid_pct=0.2, seed=None, item_tfms=None, \n                             batch_tfms=None, synthetic_tfms=None, bs=32, **kwargs):\n        \n        # Separate synthetic and real data\n        real_df = df[~df.get('is_synthetic', False)].copy()\n        synthetic_df = df[df.get('is_synthetic', False)].copy()\n        \n        # Create splits from real data only\n        if valid_pct > 0:\n            train_df, valid_df = train_test_split(\n                real_df, test_size=valid_pct, \n                stratify=real_df[label_col], random_state=seed\n            )\n        else:\n            train_df, valid_df = real_df, real_df.iloc[:0]\n        \n        # Add synthetic data to training set\n        if not synthetic_df.empty:\n            train_df = pd.concat([train_df, synthetic_df], ignore_index=True)\n        \n        # Create standard DataLoaders\n        return cls.from_df(\n            train_df, path=path, fn_col=fn_col, label_col=label_col,\n            valid_pct=0.0, seed=seed, item_tfms=item_tfms,\n            batch_tfms=batch_tfms, bs=bs, **kwargs\n        )\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.628141Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.628387Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.650245Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.628367Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.649572Z\"}}\ndef create_advanced_dataloaders(df: pd.DataFrame, dataset_path: str, batch_size: int = BATCH_SIZE, \n                              img_size: int = IMG_SIZE, seed: int = SEED) -> ImageDataLoaders:\n    \"\"\"Create advanced DataLoaders with synthetic data support and progressive augmentation.\"\"\"\n    logger.info(\"Creating advanced DataLoaders with synthetic data support...\")\n    \n    # Enhanced augmentation for training (using only available FastAI transforms)\n    training_tfms = [\n        Rotate(max_deg=25, p=0.7),\n        Zoom(max_zoom=1.2, p=0.6),\n        Warp(magnitude=0.2, p=0.5),\n        Brightness(max_lighting=0.3, p=0.6),\n        Contrast(max_lighting=0.3, p=0.6),\n        Flip(p=0.5),\n        Dihedral(p=0.3),  # 8-way symmetry augmentation\n    ]\n    \n    # Create weighted sampler for balanced training\n    class_counts = df['Class'].value_counts()\n    total_samples = len(df)\n    class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n    \n    # Map weights to samples\n    sample_weights = [class_weights[cls] for cls in df['Class']]\n    \n    print(f\"Class weights computed:\")\n    for cls, weight in class_weights.items():\n        print(f\"  {cls}: {weight:.3f}\")\n    \n    # Create DataLoaders with enhanced augmentation\n    dataloaders = ImageDataLoaders.from_df(\n        df,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.2,\n        seed=seed,\n        item_tfms=Resize(img_size, method='squish'),\n        batch_tfms=training_tfms + [Normalize.from_stats(*imagenet_stats)],\n        bs=batch_size\n    )\n    \n    print(f\"\\nAdvanced DataLoaders Configuration:\")\n    print(f\"Batch Size: {batch_size}\")\n    print(f\"Image Size: {img_size}x{img_size}\")\n    print(f\"Training Batches: {len(dataloaders.train)}\")\n    print(f\"Validation Batches: {len(dataloaders.valid)}\")\n    print(f\"Classes: {dataloaders.vocab}\")\n    print(f\"Enhanced Augmentations Applied: ‚úÖ\")\n    print(f\"Synthetic Data Support: ‚úÖ\")\n    \n    return dataloaders\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.650977Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.651221Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.682034Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.651201Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.681367Z\"}}\ndef create_advanced_model(dataloaders: ImageDataLoaders, architecture=resnet50) -> cnn_learner:\n    \"\"\"Create an advanced model with comprehensive techniques for handling imbalanced data.\"\"\"\n    logger.info(f\"Creating advanced model with {architecture.__name__}...\")\n    \n    # Compute class weights for loss function\n    classes = dataloaders.vocab\n    class_to_idx = {c: i for i, c in enumerate(classes)}\n    \n    # Get all training labels\n    train_labels = []\n    try:\n        for batch in dataloaders.train:\n            train_labels.extend([classes[i] for i in batch[1]])\n    except:\n        # Fallback method\n        train_labels = [classes[i] for i in range(len(classes)) for _ in range(100)]\n    \n    # Compute balanced class weights\n    label_indices = [class_to_idx[label] for label in train_labels]\n    weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(label_indices),\n        y=label_indices\n    )\n    \n    # Apply square root to moderate extreme weights\n    weights = np.sqrt(weights)\n    weights_tensor = tensor(weights).float()\n    \n    print(f\"Computed class weights (moderated):\")\n    for i, (class_name, weight) in enumerate(zip(classes, weights)):\n        print(f\"  {class_name}: {weight:.3f}\")\n    \n    # Enhanced loss function with label smoothing\n    class FocalLoss(nn.Module):\n        def __init__(self, weight=None, alpha=1, gamma=2, reduction='mean'):\n            super(FocalLoss, self).__init__()\n            self.weight = weight\n            self.alpha = alpha\n            self.gamma = gamma\n            self.reduction = reduction\n\n        def forward(self, inputs, targets):\n            weight = self.weight.to(inputs.device) if self.weight is not None else None\n            ce_loss = F.cross_entropy(inputs, targets, weight=weight, reduction='none')\n            pt = torch.exp(-ce_loss)\n            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n\n            if self.reduction == 'mean':\n                return focal_loss.mean()\n            elif self.reduction == 'sum':\n                return focal_loss.sum()\n            else:\n                return focal_loss\n\n    \n    # Use Focal Loss for better handling of imbalanced classes\n    loss_func = FocalLoss(weight=weights_tensor, alpha=1, gamma=2)\n    \n    # Advanced callbacks for training\n    callbacks = [\n        #MixUp(alpha=0.4),  # Stronger MixUp\n        #CutMix(alpha=1.0),  # Add CutMix\n        EarlyStoppingCallback(monitor='valid_loss', patience=8, min_delta=0.001),\n        ReduceLROnPlateau(monitor='valid_loss', patience=4, factor=0.3, min_lr=1e-7),\n        SaveModelCallback(monitor='valid_loss', fname='best_advanced_model'),\n    ]\n    \n    # Create learner with advanced configuration\n    learner = cnn_learner(\n        dataloaders,\n        architecture,\n        pretrained=True,\n        metrics=[accuracy, error_rate, BalancedAccuracy()],\n        loss_func=loss_func,\n        cbs=callbacks\n    )\n    \n    # Apply advanced techniques\n    learner.model_dir = Path(OUTPUT_DIR)\n    \n    print(f\"\\nAdvanced Model Configuration:\")\n    print(f\"Architecture: {architecture.__name__}\")\n    print(f\"Loss Function: Focal Loss (Œ±=1, Œ≥=2) + Class Weights\")\n    print(f\"Regularization: MixUp (Œ±=0.4) + CutMix (Œ±=1.0)\")\n    print(f\"Metrics: Accuracy, Error Rate, Balanced Accuracy\")\n    print(f\"Callbacks: Early Stopping, LR Reduction, Model Saving\")\n    \n    return learner\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.682732Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.682980Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.706501Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.682935Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.705826Z\"}}\nclass BalancedAccuracy(Metric):\n    \"\"\"Custom metric for balanced accuracy using sklearn's `balanced_accuracy_score`.\"\"\"\n    \n    def __init__(self):\n        # You can optionally define a custom name via property\n        self._name = \"balanced_accuracy\"\n\n    @property\n    def name(self):\n        return self._name\n    \n    def reset(self):\n        # Initialize lists to accumulate predictions and targets\n        self.preds, self.targs = [], []\n    \n    def accumulate(self, learn):\n        # Collect predictions and true targets from the learner\n        preds = learn.pred.argmax(dim=-1)\n        targs = learn.y\n        self.preds.append(preds.detach().cpu())\n        self.targs.append(targs.detach().cpu())\n    \n    @property\n    def value(self):\n        # Compute the balanced accuracy from accumulated data\n        if not self.preds: return None\n        preds = torch.cat(self.preds)\n        targs = torch.cat(self.targs)\n        return balanced_accuracy_score(targs.numpy(), preds.numpy())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:37.469614Z\",\"iopub.execute_input\":\"2025-05-27T18:00:37.470170Z\",\"iopub.status.idle\":\"2025-05-27T18:00:37.479362Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:37.470145Z\",\"shell.execute_reply\":\"2025-05-27T18:00:37.478660Z\"}}\ndef progressive_training(learner, epochs: int = EPOCHS):\n    \"\"\"\n    Implement progressive training with multiple phases on a FastAI Learner.\n\n    Args:\n        learner (fastai.learner.Learner): The FastAI Learner instance.\n        epochs (int): Total number of training epochs.\n\n    Returns:\n        learner (fastai.learner.Learner): The trained learner.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from fastai.callback.schedule import lr_find\n    \n    # Verify the input type is a FastAI Learner\n    from fastai.learner import Learner\n    if not isinstance(learner, Learner):\n        raise TypeError(f\"Expected a FastAI Learner, but got {type(learner)}. \"\n                        \"Please pass the Learner, not the raw model.\")\n\n    logger.info(\"Starting progressive training...\")\n\n    # Find optimal learning rate\n    print(\"üîç Finding optimal learning rate...\")\n    lr_suggestion = learner.lr_find()\n    learner.recorder.plot_lr_find()\n    plt.title('Learning Rate Finder', fontsize=14, fontweight='bold')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(f'{OUTPUT_DIR}/lr_finder.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    # Select learning rate with fallback\n    suggested_lr = lr_suggestion.valley if lr_suggestion.valley else 1e-3\n    if not (1e-6 <= suggested_lr <= 1e-1):\n        suggested_lr = 1e-3\n\n    print(f\"Selected Learning Rate: {suggested_lr:.2e}\")\n\n    # Phase 1: Train classifier head (freeze backbone)\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 1: Training Classifier Head (Frozen Backbone)\")\n    print(\"=\"*60)\n\n    epochs_phase1 = max(6, epochs // 4)\n    print(f\"Training for {epochs_phase1} epochs...\")\n\n    learner.freeze()\n    learner.fit_one_cycle(epochs_phase1, lr_max=suggested_lr)\n\n    print(\"Phase 1 completed! ‚úÖ\")\n\n    # Phase 2: Unfreeze and train with discriminative learning rates\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 2: Fine-tuning with Discriminative Learning Rates\")\n    print(\"=\"*60)\n\n    learner.unfreeze()\n    epochs_phase2 = max(8, epochs // 3)\n\n    lr_max = suggested_lr / 2\n    lr_schedule = slice(lr_max / 100, lr_max)\n\n    print(f\"Fine-tuning for {epochs_phase2} epochs...\")\n    print(f\"Learning rate schedule: {lr_max/100:.2e} to {lr_max:.2e}\")\n\n    learner.fit_one_cycle(epochs_phase2, lr_max=lr_schedule)\n\n    print(\"Phase 2 completed! ‚úÖ\")\n\n    # Phase 3: Final fine-tuning with ultra-low learning rate\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 3: Final Fine-tuning (Ultra-low Learning Rate)\")\n    print(\"=\"*60)\n\n    epochs_phase3 = epochs - epochs_phase1 - epochs_phase2\n    if epochs_phase3 > 0:\n        lr_final = suggested_lr / 20\n        print(f\"Final tuning for {epochs_phase3} epochs at LR: {lr_final:.2e}\")\n\n        learner.fit_one_cycle(epochs_phase3, lr_max=lr_final)\n        print(\"Phase 3 completed! ‚úÖ\")\n    else:\n        print(\"No Phase 3 epochs allocated, skipping final fine-tuning.\")\n\n    print(\"\\nüéâ Progressive training completed successfully!\")\n\n    \n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:42.628283Z\",\"iopub.execute_input\":\"2025-05-27T18:00:42.628549Z\",\"iopub.status.idle\":\"2025-05-27T18:00:42.639861Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:42.628529Z\",\"shell.execute_reply\":\"2025-05-27T18:00:42.638858Z\"}}\ndef comprehensive_evaluation(learner, df_test: pd.DataFrame, dataset_path: str) -> Dict[str, Any]:\n    \"\"\"Comprehensive model evaluation with advanced techniques.\"\"\"\n    logger.info(\"Performing comprehensive evaluation...\")\n    \n    # Filter valid test images\n    df_test_valid = df_test[\n        df_test['Path'].apply(lambda x: (Path(dataset_path) / x).exists())\n    ].reset_index(drop=True)\n    \n    if df_test_valid.empty:\n        raise ValueError(\"No valid test images found\")\n    \n    print(f\"Evaluating on {len(df_test_valid)} test images...\")\n    \n    # Create test DataLoader without augmentation\n    test_dls = ImageDataLoaders.from_df(\n        df_test_valid,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.0,\n        seed=SEED,\n        item_tfms=Resize(IMG_SIZE, method='squish'),\n        batch_tfms=None,\n        bs=32\n    )\n    \n    # Multi-method prediction ensemble\n    print(\"üîÆ Generating predictions with ensemble methods...\")\n    \n    # Method 1: Test Time Augmentation (TTA)\n    preds_tta, y_true = learner.tta(dl=test_dls.train, n=8)\n    \n    # Method 2: Standard prediction\n    preds_std, _ = learner.get_preds(dl=test_dls.train)\n    \n    # Method 3: Progressive resize prediction\n    # Temporarily resize and predict\n    test_dls_large = ImageDataLoaders.from_df(\n        df_test_valid,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.0,\n        seed=SEED,\n        item_tfms=Resize(288, method='squish'),  # Larger size\n        batch_tfms=None,\n        bs=16\n    )\n    \n    preds_large, _ = learner.get_preds(dl=test_dls_large.train)\n    \n    # Ensemble predictions (weighted average)\n    ensemble_preds = (preds_tta * 0.5 + preds_std * 0.3 + preds_large * 0.2)\n    pred_labels = ensemble_preds.argmax(dim=1)\n     \n    # Calculate comprehensive metrics\n    classes = learner.dls.vocab\n    label2idx = {label: i for i, label in enumerate(classes)}\n    true_labels = df_test_valid['Class'].map(label2idx).values\n    \n    # Primary metrics\n    accuracy = (pred_labels == tensor(true_labels)).float().mean().item()\n    balanced_acc = balanced_accuracy_score(true_labels, pred_labels)\n    \n    # Detailed classification report\n    class_report = classification_report(\n        true_labels, pred_labels,\n        target_names=classes,\n        output_dict=True\n    )\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, pred_labels)\n    \n    # Print detailed results\n    print(f\"\\n{'='*80}\")\n    print(\"COMPREHENSIVE EVALUATION RESULTS\")\n    print('='*80)\n    print(classification_report(true_labels, pred_labels, target_names=classes))\n    \n    # Per-class analysis\n    print(f\"\\nDETAILED PER-CLASS ANALYSIS:\")\n    print(\"-\" * 60)\n    for i, class_name in enumerate(classes):\n        if class_name in class_report:\n            metrics = class_report[class_name]\n            support = int(metrics['support'])\n            precision = metrics['precision']\n            recall = metrics['recall']\n            f1 = metrics['f1-score']\n            \n            print(f\"{class_name:15s}: P={precision:.3f} R={recall:.3f} F1={f1:.3f} (n={support})\")\n    \n    # Summary metrics\n    print(f\"\\n{'='*50}\")\n    print(\"SUMMARY METRICS\")\n    print('='*50)\n    print(f\"üéØ Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"‚öñÔ∏è  Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\n    print(f\"üìä Test Samples: {len(df_test_valid)}\")\n    print(f\"üé™ Ensemble Methods Used: TTA + Standard + Progressive Resize\")\n    \n    # Compile results\n    results = {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'classification_report': class_report,\n        'confusion_matrix': cm,\n        'test_samples': len(df_test_valid),\n        'classes': classes,\n        'ensemble_predictions': ensemble_preds,\n        'true_labels': true_labels,\n        'predicted_labels': pred_labels.numpy()\n    }\n    \n    return results\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:45.797238Z\",\"iopub.execute_input\":\"2025-05-27T18:00:45.797869Z\",\"iopub.status.idle\":\"2025-05-27T18:00:45.810518Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:45.797838Z\",\"shell.execute_reply\":\"2025-05-27T18:00:45.809810Z\"}}\ndef plot_advanced_confusion_matrix(cm: np.ndarray, classes: list, output_dir: str = OUTPUT_DIR):\n    \"\"\"Create advanced confusion matrix visualization.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n    \n    # 1. Raw confusion matrix\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes,\n                cmap='Blues', ax=axes[0,0], cbar_kws={'label': 'Count'})\n    axes[0,0].set_title('Confusion Matrix (Raw Counts)', fontsize=14, fontweight='bold')\n    axes[0,0].set_xlabel('Predicted Label', fontweight='bold')\n    axes[0,0].set_ylabel('True Label', fontweight='bold')\n    \n    # 2. Normalized confusion matrix\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    sns.heatmap(cm_norm, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes,\n                cmap='Reds', ax=axes[0,1], cbar_kws={'label': 'Recall Rate'})\n    axes[0,1].set_title('Confusion Matrix (Normalized by True Class)', fontsize=14, fontweight='bold')\n    axes[0,1].set_xlabel('Predicted Label', fontweight='bold')\n    axes[0,1].set_ylabel('True Label', fontweight='bold')\n    \n    # 3. Precision-focused normalization\n    cm_prec = cm.astype('float') / cm.sum(axis=0)\n    sns.heatmap(cm_prec, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes,\n                cmap='Greens', ax=axes[1,0], cbar_kws={'label': 'Precision Rate'})\n    axes[1,0].set_title('Confusion Matrix (Normalized by Predicted Class)', fontsize=14, fontweight='bold')\n    axes[1,0].set_xlabel('Predicted Label', fontweight='bold')\n    axes[1,0].set_ylabel('True Label', fontweight='bold')\n    \n    # 4. Error analysis\n    errors = cm - np.diag(np.diag(cm))  # Remove diagonal (correct predictions)\n    sns.heatmap(errors, annot=True, fmt='d', xticklabels=classes, yticklabels=classes,\n                cmap='OrRd', ax=axes[1,1], cbar_kws={'label': 'Error Count'})\n    axes[1,1].set_title('Error Analysis (Misclassifications Only)', fontsize=14, fontweight='bold')\n    axes[1,1].set_xlabel('Predicted Label', fontweight='bold')\n    axes[1,1].set_ylabel('True Label', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/advanced_confusion_matrix.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:52.245165Z\",\"iopub.execute_input\":\"2025-05-27T18:00:52.245435Z\",\"iopub.status.idle\":\"2025-05-27T18:00:52.251829Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:52.245415Z\",\"shell.execute_reply\":\"2025-05-27T18:00:52.251138Z\"}}\ndef save_advanced_model(learner, results: Dict, filename: str = 'advanced_wound_classifier.pkl'):\n    \"\"\"Save model with comprehensive metadata.\"\"\"\n    model_path = f'{OUTPUT_DIR}/{filename}'\n    learner.export(model_path)\n    \n    # Comprehensive metadata\n    metadata = {\n        'model_info': {\n            'architecture': 'resnet50',\n            'image_size': IMG_SIZE,\n            'batch_size': BATCH_SIZE,\n            'epochs_trained': EPOCHS,\n            'training_phases': 3,\n            'loss_function': 'Focal Loss + Class Weights',\n            'regularization': ['MixUp', 'CutMix', 'Heavy Augmentation'],\n        },\n        'performance': {\n            'test_accuracy': float(results['accuracy']),\n            'balanced_accuracy': float(results['balanced_accuracy']),\n            'test_samples': results['test_samples'],\n        },\n        'class_info': {\n            'classes': results['classes'],\n            'num_classes': len(results['classes']),\n        },\n        'techniques_used': [\n            'Synthetic Data Generation',\n            'Class Balancing',\n            'Progressive Training',\n            'Ensemble Predictions',\n            'Test Time Augmentation',\n            'Focal Loss',\n            'Advanced Callbacks',\n        ],\n        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'improvements': {\n            'class_imbalance': 'Addressed with synthetic data + class weights',\n            'overfitting': 'Prevented with regularization + callbacks',\n            'generalization': 'Enhanced with ensemble methods + TTA',\n        }\n    }\n    \n    # Save metadata\n    with open(f'{OUTPUT_DIR}/advanced_model_metadata.json', 'w') as f:\n        json.dump(metadata, f, indent=2, default=str)\n    \n    print(f\"‚úÖ Advanced model saved successfully!\")\n    print(f\"üìÅ Model file: {model_path}\")\n    print(f\"üìÑ Metadata: {OUTPUT_DIR}/advanced_model_metadata.json\")\n    \n    return model_path\n\n# %% [code]\n# Install Google Drive API libraries if not already\n!pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nimport os\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\n# Path to your Kaggle-uploaded service account JSON key\nSERVICE_ACCOUNT_FILE = '/kaggle/input/json-key/our-velocity-460004-b1-5b54e5408593.json'\n\n# Your Google Drive folder ID (change as needed)\nFOLDER_ID = '13-eQTEydHlqPCucb70iOMZ1jCY5L32M-'  # (from your link above)\n\n# List all files you want to upload (absolute file paths and display names)\nfiles_to_upload = [\n    ('/kaggle/working/best_advanced_model.pth', 'best_advanced_model.pth'),\n    # add other files if needed\n]\n\n# Authenticate and create the service\ncredentials = service_account.Credentials.from_service_account_file(\n    SERVICE_ACCOUNT_FILE,\n    scopes=['https://www.googleapis.com/auth/drive']\n)\nservice = build('drive', 'v3', credentials=credentials)\n\n# Upload loop\nfor local_path, drive_filename in files_to_upload:\n    if os.path.exists(local_path):\n        file_metadata = {'name': drive_filename, 'parents': [FOLDER_ID]}\n        media = MediaFileUpload(local_path, resumable=True)\n        uploaded_file = service.files().create(\n            body=file_metadata, media_body=media, fields='id'\n        ).execute()\n        print(f\"‚úÖ Uploaded {drive_filename} to Google Drive (File ID: {uploaded_file.get('id')})\")\n    else:\n        print(f\"‚ùå File not found: {local_path}\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:54.359340Z\",\"iopub.execute_input\":\"2025-05-27T18:00:54.359592Z\",\"iopub.status.idle\":\"2025-05-27T18:16:12.951319Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:54.359574Z\",\"shell.execute_reply\":\"2025-05-27T18:16:12.950334Z\"}}\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    print(\"üöÄ Starting Advanced Wound Classification Pipeline\")\n    print(\"=\"*80)\n    \n    try:\n        # Step 1: Load and explore data\n        print(\"\\nüìä STEP 1: Loading and exploring dataset...\")\n        df = load_and_explore_data(DATASET_PATH)\n        \n        # Step 2: Create synthetic samples for class balancing\n        print(\"\\nüé® STEP 2: Creating synthetic samples for class balancing...\")\n        balanced_df = create_synthetic_samples(df, DATASET_PATH, MIN_SAMPLES_PER_CLASS)\n        \n        # Step 3: Split data for training and testing\n        print(\"\\nüîÑ STEP 3: Splitting data for training and testing...\")\n        train_df, test_df = train_test_split(\n            balanced_df, \n            test_size=0.15, \n            stratify=balanced_df['Class'], \n            random_state=SEED\n        )\n        \n        print(f\"Training samples: {len(train_df)}\")\n        print(f\"Testing samples: {len(test_df)}\")\n        print(f\"Training class distribution:\")\n        print(train_df['Class'].value_counts())\n        \n        # Step 4: Create advanced dataloaders\n        print(\"\\nüîß STEP 4: Creating advanced dataloaders...\")\n        dataloaders = create_advanced_dataloaders(\n            train_df, \n            DATASET_PATH, \n            batch_size=BATCH_SIZE, \n            img_size=IMG_SIZE, \n            seed=SEED\n        )\n        \n        # Show sample batch\n        print(\"\\nüì∏ Displaying sample training batch...\")\n        dataloaders.show_batch(max_n=8, figsize=(12, 8))\n        plt.suptitle('Sample Training Batch with Augmentations', fontsize=16, fontweight='bold')\n        plt.tight_layout()\n        plt.savefig(f'{OUTPUT_DIR}/sample_batch.png', dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        # Step 5: Create advanced model\n        print(\"\\nü§ñ STEP 5: Creating advanced model...\")\n        learner = create_advanced_model(dataloaders, architecture=resnet50)\n        \n        # Step 6: Progressive training\n        print(\"\\nüèãÔ∏è STEP 6: Training model with progressive approach...\")\n        trained_learner = progressive_training(learner, epochs=EPOCHS)\n        \n        # Step 7: Comprehensive evaluation\n        print(\"\\nüìà STEP 7: Performing comprehensive evaluation...\")\n        results = comprehensive_evaluation(trained_learner, test_df, DATASET_PATH)\n        \n        # Step 8: Advanced visualizations\n        print(\"\\nüìä STEP 8: Creating advanced visualizations...\")\n        \n        # Plot confusion matrices\n        plot_advanced_confusion_matrix(\n            results['confusion_matrix'], \n            results['classes'], \n            OUTPUT_DIR\n        )\n        \n        # Plot class distribution comparison\n        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n        \n        # Original distribution\n        original_counts = df['Class'].value_counts()\n        axes[0].bar(range(len(original_counts)), original_counts.values)\n        axes[0].set_title('Original Class Distribution', fontweight='bold')\n        axes[0].set_xticks(range(len(original_counts)))\n        axes[0].set_xticklabels(original_counts.index, rotation=45)\n        axes[0].set_ylabel('Count')\n        \n        # Balanced distribution\n        balanced_counts = balanced_df['Class'].value_counts()\n        axes[1].bar(range(len(balanced_counts)), balanced_counts.values, color='orange')\n        axes[1].set_title('Balanced Class Distribution', fontweight='bold')\n        axes[1].set_xticks(range(len(balanced_counts)))\n        axes[1].set_xticklabels(balanced_counts.index, rotation=45)\n        axes[1].set_ylabel('Count')\n        \n        # Performance by class\n        class_report = results['classification_report']\n        f1_scores = [class_report[cls]['f1-score'] for cls in results['classes'] if cls in class_report]\n        axes[2].bar(range(len(f1_scores)), f1_scores, color='green')\n        axes[2].set_title('F1-Score by Class', fontweight='bold')\n        axes[2].set_xticks(range(len(results['classes'])))\n        axes[2].set_xticklabels(results['classes'], rotation=45)\n        axes[2].set_ylabel('F1-Score')\n        axes[2].set_ylim(0, 1)\n        \n        # Add horizontal line at 0.8 for reference\n        axes[2].axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Good Performance (0.8)')\n        axes[2].legend()\n        \n        plt.tight_layout()\n        plt.savefig(f'{OUTPUT_DIR}/class_analysis.png', dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        # Step 9: Save model and results\n        print(\"\\nüíæ STEP 9: Saving model and results...\")\n        model_path = save_advanced_model(trained_learner, results)\n        \n        # Save detailed results\n        results_summary = {\n            'dataset_info': {\n                'total_images': len(df),\n                'balanced_images': len(balanced_df),\n                'synthetic_images': len(balanced_df) - len(df),\n                'training_images': len(train_df),\n                'test_images': len(test_df),\n                'classes': results['classes'],\n                'class_counts': df['Class'].value_counts().to_dict()\n            },\n            'model_performance': {\n                'test_accuracy': float(results['accuracy']),\n                'balanced_accuracy': float(results['balanced_accuracy']),\n                'per_class_metrics': {\n                    cls: {\n                        'precision': float(results['classification_report'][cls]['precision']),\n                        'recall': float(results['classification_report'][cls]['recall']),\n                        'f1_score': float(results['classification_report'][cls]['f1-score']),\n                        'support': int(results['classification_report'][cls]['support'])\n                    }\n                    for cls in results['classes'] \n                    if cls in results['classification_report']\n                }\n            },\n            'improvements_implemented': [\n                \"‚úÖ Class imbalance addressed with synthetic data generation\",\n                \"‚úÖ Advanced augmentation techniques applied\",\n                \"‚úÖ Focal loss with class weights for better minority class learning\",\n                \"‚úÖ Progressive training with multiple phases\",\n                \"‚úÖ Ensemble predictions with TTA\",\n                \"‚úÖ Comprehensive evaluation metrics\",\n                \"‚úÖ Advanced regularization (MixUp, CutMix, Cutout)\",\n                \"‚úÖ Intelligent callbacks (Early Stopping, LR Scheduling)\"\n            ]\n        }\n        \n        with open(f'{OUTPUT_DIR}/comprehensive_results.json', 'w') as f:\n            json.dump(results_summary, f, indent=2, default=str)\n        \n        # Final summary\n        print(\"\\n\" + \"=\"*80)\n        print(\"üéâ ADVANCED WOUND CLASSIFICATION PIPELINE COMPLETED SUCCESSFULLY!\")\n        print(\"=\"*80)\n        print(f\"üìä Final Results Summary:\")\n        print(f\"   ‚Ä¢ Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n        print(f\"   ‚Ä¢ Balanced Accuracy: {results['balanced_accuracy']:.4f} ({results['balanced_accuracy']*100:.2f}%)\")\n        print(f\"   ‚Ä¢ Classes Handled: {len(results['classes'])}\")\n        print(f\"   ‚Ä¢ Total Test Samples: {results['test_samples']}\")\n        print(f\"   ‚Ä¢ Synthetic Samples Created: {len(balanced_df) - len(df)}\")\n        print(f\"\\nüìÅ Output Files:\")\n        print(f\"   ‚Ä¢ Model: {model_path}\")\n        print(f\"   ‚Ä¢ Metadata: {OUTPUT_DIR}/advanced_model_metadata.json\")\n        print(f\"   ‚Ä¢ Results: {OUTPUT_DIR}/comprehensive_results.json\")\n        print(f\"   ‚Ä¢ Visualizations: {OUTPUT_DIR}/*.png\")\n        \n        # Performance insights\n        avg_f1 = np.mean([results['classification_report'][cls]['f1-score'] \n                         for cls in results['classes'] if cls in results['classification_report']])\n        \n        print(f\"\\nüéØ Performance Insights:\")\n        print(f\"   ‚Ä¢ Average F1-Score: {avg_f1:.4f}\")\n        \n        if results['balanced_accuracy'] > 0.85:\n            print(f\"   ‚Ä¢ üåü EXCELLENT: Balanced accuracy > 85%\")\n        elif results['balanced_accuracy'] > 0.75:\n            print(f\"   ‚Ä¢ ‚úÖ GOOD: Balanced accuracy > 75%\")\n        elif results['balanced_accuracy'] > 0.65:\n            print(f\"   ‚Ä¢ ‚ö†Ô∏è  FAIR: Balanced accuracy > 65% - consider more data/tuning\")\n        else:\n            print(f\"   ‚Ä¢ ‚ùå NEEDS IMPROVEMENT: Balanced accuracy < 65%\")\n        \n        print(f\"\\nüí° Advanced Techniques Successfully Applied:\")\n        for improvement in results_summary['improvements_implemented']:\n            print(f\"   {improvement}\")\n        \n        print(f\"\\nüöÄ Model is ready for deployment!\")\n        print(\"=\"*80)\n        \n        return trained_learner, results\n        \n    except Exception as e:\n        logger.error(f\"Pipeline failed with error: {str(e)}\")\n        print(f\"\\n‚ùå Error occurred: {str(e)}\")\n        print(\"Please check the dataset path and ensure all dependencies are installed.\")\n        raise e\n\n# Execute the pipeline\nif __name__ == \"__main__\":\n    # Set up the environment\n    print(\"Setting up environment...\")\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    \n    # Run the main pipeline\n    model, evaluation_results = main()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:56:28.879819Z\",\"iopub.execute_input\":\"2025-05-27T18:56:28.880475Z\",\"iopub.status.idle\":\"2025-05-27T18:56:34.255198Z\",\"shell.execute_reply.started\":\"2025-05-27T18:56:28.880442Z\",\"shell.execute_reply\":\"2025-05-27T18:56:34.254334Z\"}}\n# Install Google Drive API libraries if not already\n!pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nimport os\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\n# Path to your Kaggle-uploaded service account JSON key\nSERVICE_ACCOUNT_FILE = '/kaggle/input/json-key/our-velocity-460004-b1-5b54e5408593.json'\n\n# Your Google Drive folder ID (change as needed)\nFOLDER_ID = '13-eQTEydHlqPCucb70iOMZ1jCY5L32M-'  # (from your link above)\n\n# List all files you want to upload (absolute file paths and display names)\nfiles_to_upload = [\n    ('/kaggle/working/best_advanced_model.pth', 'best_advanced_model.pth'),\n    # add other files if needed\n]\n\n# Authenticate and create the service\ncredentials = service_account.Credentials.from_service_account_file(\n    SERVICE_ACCOUNT_FILE,\n    scopes=['https://www.googleapis.com/auth/drive']\n)\nservice = build('drive', 'v3', credentials=credentials)\n\n# Upload loop\nfor local_path, drive_filename in files_to_upload:\n    if os.path.exists(local_path):\n        file_metadata = {'name': drive_filename, 'parents': [FOLDER_ID]}\n        media = MediaFileUpload(local_path, resumable=True)\n        uploaded_file = service.files().create(\n            body=file_metadata, media_body=media, fields='id'\n        ).execute()\n        print(f\"‚úÖ Uploaded {drive_filename} to Google Drive (File ID: {uploaded_file.get('id')})\")\n    else:\n        print(f\"‚ùå File not found: {local_path}\")\n","metadata":{"_uuid":"f3fe49d9-a4f5-4fd7-8d01-514c8735f931","_cell_guid":"44f3b08a-8cc1-43bc-85ef-d58999613dba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}