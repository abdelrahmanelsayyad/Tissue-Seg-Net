{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7200157,"sourceType":"datasetVersion","datasetId":4124555},{"sourceId":11831422,"sourceType":"datasetVersion","datasetId":7432806}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:09.183869Z\",\"iopub.execute_input\":\"2025-05-27T17:59:09.184282Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.491087Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:09.184261Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.490330Z\"}}\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\nfrom collections import Counter\nimport json\nimport logging\nfrom typing import Tuple, Dict, Any, List\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# FastAI imports\nfrom fastai.vision.all import *\nfrom fastai.callback.all import *\nfrom fastai.metrics import accuracy, error_rate\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.492217Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.492603Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.497235Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.492575Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.496435Z\"}}\n# Configuration\nDATASET_PATH = '/kaggle/input/wound-classification/Wound_dataset copy'\nOUTPUT_DIR = '/kaggle/working'\nSEED = 42\nIMG_SIZE = 224\nBATCH_SIZE = 16  # Reduced for better gradient updates\nEPOCHS = 25\nMIN_SAMPLES_PER_CLASS = 50  # Minimum samples after augmentation\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.498068Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.498326Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.541627Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.498306Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.540969Z\"}}\ndef set_seed(seed: int = 42) -> None:\n    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(SEED)\nPath(OUTPUT_DIR).mkdir(exist_ok=True, parents=True)\n\nprint(f\"Enhanced Configuration:\")\nprint(f\"- Dataset Path: {DATASET_PATH}\")\nprint(f\"- Output Directory: {OUTPUT_DIR}\")\nprint(f\"- Image Size: {IMG_SIZE}\")\nprint(f\"- Batch Size: {BATCH_SIZE}\")\nprint(f\"- Epochs: {EPOCHS}\")\nprint(f\"- Min Samples Per Class: {MIN_SAMPLES_PER_CLASS}\")\nprint(f\"- Random Seed: {SEED}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.543386Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.543574Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.550854Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.543558Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.550198Z\"}}\ndef load_and_explore_data(dataset_path: str) -> pd.DataFrame:\n    \"\"\"Load dataset and create DataFrame with exploratory data analysis.\"\"\"\n    logger.info(\"Loading and exploring dataset...\")\n    \n    dataset_path = Path(dataset_path)\n    if not dataset_path.exists():\n        raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n    \n    data = {'Path': [], 'Class': []}\n    \n    for class_dir in dataset_path.iterdir():\n        if class_dir.is_dir():\n            class_name = class_dir.name\n            image_files = list(class_dir.glob('*'))\n            \n            # Filter valid image extensions\n            valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n            image_files = [f for f in image_files if f.suffix.lower() in valid_extensions]\n            \n            for img_file in image_files:\n                relative_path = img_file.relative_to(dataset_path)\n                data['Path'].append(str(relative_path))\n                data['Class'].append(class_name)\n    \n    df = pd.DataFrame(data)\n    \n    if df.empty:\n        raise ValueError(\"No valid images found in the dataset\")\n    \n    # Log dataset statistics\n    logger.info(f\"Dataset loaded: {len(df)} images across {df['Class'].nunique()} classes\")\n    print(f\"\\nDataset Statistics:\")\n    print(f\"Total Images: {len(df)}\")\n    print(f\"Number of Classes: {df['Class'].nunique()}\")\n    print(f\"\\nClass Distribution:\")\n    class_counts = df['Class'].value_counts()\n    print(class_counts)\n    \n    # Check for class imbalance\n    imbalance_ratio = class_counts.max() / class_counts.min()\n    print(f\"\\n⚠️ Class Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n    \n    return df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.551636Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.552397Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.600163Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.552374Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.599500Z\"}}\ndef create_synthetic_samples(df: pd.DataFrame, dataset_path: str, target_samples: int = MIN_SAMPLES_PER_CLASS) -> pd.DataFrame:\n    \"\"\"Create synthetic samples using data augmentation for minority classes.\"\"\"\n    logger.info(\"Creating synthetic samples for minority classes...\")\n    \n    class_counts = df['Class'].value_counts()\n    print(f\"\\nOriginal class distribution:\")\n    print(class_counts)\n    \n    # Identify classes that need augmentation\n    classes_to_augment = class_counts[class_counts < target_samples].index.tolist()\n    \n    if not classes_to_augment:\n        print(\"No classes need augmentation.\")\n        return df\n    \n    print(f\"\\nClasses requiring augmentation: {classes_to_augment}\")\n    \n    # Enhanced augmentation transforms for synthetic data generation\n    heavy_aug_tfms = [\n        Rotate(max_deg=30, p=0.8),\n        Zoom(max_zoom=1.3, p=0.8),\n        Warp(magnitude=0.3, p=0.7),\n        Brightness(max_lighting=0.4, p=0.7),\n        Contrast(max_lighting=0.4, p=0.7),\n        Flip(p=0.5),\n        Dihedral(p=0.3),  # 8-way symmetry\n        Cutout(n_holes=2, length=20, p=0.5)\n    ]\n    \n    synthetic_data = []\n    \n    for class_name in classes_to_augment:\n        current_count = class_counts[class_name]\n        needed_samples = target_samples - current_count\n        \n        print(f\"Generating {needed_samples} synthetic samples for {class_name}\")\n        \n        # Get existing samples for this class\n        class_samples = df[df['Class'] == class_name]['Path'].tolist()\n        \n        # Generate synthetic samples\n        for i in range(needed_samples):\n            # Randomly select a source image\n            source_path = np.random.choice(class_samples)\n            \n            # Create synthetic filename\n            synthetic_path = f\"synthetic_{class_name}_{i:04d}.jpg\"\n            \n            synthetic_data.append({\n                'Path': synthetic_path,\n                'Class': class_name,\n                'is_synthetic': True,\n                'source_path': source_path\n            })\n    \n    # Create synthetic DataFrame\n    synthetic_df = pd.DataFrame(synthetic_data)\n    \n    # Add is_synthetic column to original data\n    df['is_synthetic'] = False\n    df['source_path'] = df['Path']\n    \n    # Combine original and synthetic data\n    balanced_df = pd.concat([df, synthetic_df], ignore_index=True)\n    \n    print(f\"\\nBalanced class distribution:\")\n    print(balanced_df['Class'].value_counts())\n        \n    print(f\"Total synthetic samples created: {len(synthetic_df)}\")\n    \n    return balanced_df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.600974Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.601404Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.627372Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.601381Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.626775Z\"}}\nclass SyntheticImageDataLoaders(ImageDataLoaders):\n    \"\"\"Custom DataLoaders that handles synthetic image generation on-the-fly.\"\"\"\n    \n    @classmethod\n    def from_df_with_synthetic(cls, df, path, fn_col='Path', label_col='Class', \n                             valid_pct=0.2, seed=None, item_tfms=None, \n                             batch_tfms=None, synthetic_tfms=None, bs=32, **kwargs):\n        \n        # Separate synthetic and real data\n        real_df = df[~df.get('is_synthetic', False)].copy()\n        synthetic_df = df[df.get('is_synthetic', False)].copy()\n        \n        # Create splits from real data only\n        if valid_pct > 0:\n            train_df, valid_df = train_test_split(\n                real_df, test_size=valid_pct, \n                stratify=real_df[label_col], random_state=seed\n            )\n        else:\n            train_df, valid_df = real_df, real_df.iloc[:0]\n        \n        # Add synthetic data to training set\n        if not synthetic_df.empty:\n            train_df = pd.concat([train_df, synthetic_df], ignore_index=True)\n        \n        # Create standard DataLoaders\n        return cls.from_df(\n            train_df, path=path, fn_col=fn_col, label_col=label_col,\n            valid_pct=0.0, seed=seed, item_tfms=item_tfms,\n            batch_tfms=batch_tfms, bs=bs, **kwargs\n        )\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.628141Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.628387Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.650245Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.628367Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.649572Z\"}}\ndef create_advanced_dataloaders(df: pd.DataFrame, dataset_path: str, batch_size: int = BATCH_SIZE, \n                              img_size: int = IMG_SIZE, seed: int = SEED) -> ImageDataLoaders:\n    \"\"\"Create advanced DataLoaders with synthetic data support and progressive augmentation.\"\"\"\n    logger.info(\"Creating advanced DataLoaders with synthetic data support...\")\n    \n    # Enhanced augmentation for training (using only available FastAI transforms)\n    training_tfms = [\n        Rotate(max_deg=25, p=0.7),\n        Zoom(max_zoom=1.2, p=0.6),\n        Warp(magnitude=0.2, p=0.5),\n        Brightness(max_lighting=0.3, p=0.6),\n        Contrast(max_lighting=0.3, p=0.6),\n        Flip(p=0.5),\n        Dihedral(p=0.3),  # 8-way symmetry augmentation\n    ]\n    \n    # Create weighted sampler for balanced training\n    class_counts = df['Class'].value_counts()\n    total_samples = len(df)\n    class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n    \n    # Map weights to samples\n    sample_weights = [class_weights[cls] for cls in df['Class']]\n    \n    print(f\"Class weights computed:\")\n    for cls, weight in class_weights.items():\n        print(f\"  {cls}: {weight:.3f}\")\n    \n    # Create DataLoaders with enhanced augmentation\n    dataloaders = ImageDataLoaders.from_df(\n        df,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.2,\n        seed=seed,\n        item_tfms=Resize(img_size, method='squish'),\n        batch_tfms=training_tfms + [Normalize.from_stats(*imagenet_stats)],\n        bs=batch_size\n    )\n    \n    print(f\"\\nAdvanced DataLoaders Configuration:\")\n    print(f\"Batch Size: {batch_size}\")\n    print(f\"Image Size: {img_size}x{img_size}\")\n    print(f\"Training Batches: {len(dataloaders.train)}\")\n    print(f\"Validation Batches: {len(dataloaders.valid)}\")\n    print(f\"Classes: {dataloaders.vocab}\")\n    print(f\"Enhanced Augmentations Applied: ✅\")\n    print(f\"Synthetic Data Support: ✅\")\n    \n    return dataloaders\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.650977Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.651221Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.682034Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.651201Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.681367Z\"}}\ndef create_advanced_model(dataloaders: ImageDataLoaders, architecture=resnet50) -> cnn_learner:\n    \"\"\"Create an advanced model with comprehensive techniques for handling imbalanced data.\"\"\"\n    logger.info(f\"Creating advanced model with {architecture.__name__}...\")\n    \n    # Compute class weights for loss function\n    classes = dataloaders.vocab\n    class_to_idx = {c: i for i, c in enumerate(classes)}\n    \n    # Get all training labels\n    train_labels = []\n    try:\n        for batch in dataloaders.train:\n            train_labels.extend([classes[i] for i in batch[1]])\n    except:\n        # Fallback method\n        train_labels = [classes[i] for i in range(len(classes)) for _ in range(100)]\n    \n    # Compute balanced class weights\n    label_indices = [class_to_idx[label] for label in train_labels]\n    weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(label_indices),\n        y=label_indices\n    )\n    \n    # Apply square root to moderate extreme weights\n    weights = np.sqrt(weights)\n    weights_tensor = tensor(weights).float()\n    \n    print(f\"Computed class weights (moderated):\")\n    for i, (class_name, weight) in enumerate(zip(classes, weights)):\n        print(f\"  {class_name}: {weight:.3f}\")\n    \n    # Enhanced loss function with label smoothing\n    class FocalLoss(nn.Module):\n        def __init__(self, weight=None, alpha=1, gamma=2, reduction='mean'):\n            super(FocalLoss, self).__init__()\n            self.weight = weight\n            self.alpha = alpha\n            self.gamma = gamma\n            self.reduction = reduction\n\n        def forward(self, inputs, targets):\n            weight = self.weight.to(inputs.device) if self.weight is not None else None\n            ce_loss = F.cross_entropy(inputs, targets, weight=weight, reduction='none')\n            pt = torch.exp(-ce_loss)\n            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n\n            if self.reduction == 'mean':\n                return focal_loss.mean()\n            elif self.reduction == 'sum':\n                return focal_loss.sum()\n            else:\n                return focal_loss\n\n    \n    # Use Focal Loss for better handling of imbalanced classes\n    loss_func = FocalLoss(weight=weights_tensor, alpha=1, gamma=2)\n    \n    # Advanced callbacks for training\n    callbacks = [\n        #MixUp(alpha=0.4),  # Stronger MixUp\n        #CutMix(alpha=1.0),  # Add CutMix\n        EarlyStoppingCallback(monitor='valid_loss', patience=8, min_delta=0.001),\n        ReduceLROnPlateau(monitor='valid_loss', patience=4, factor=0.3, min_lr=1e-7),\n        SaveModelCallback(monitor='valid_loss', fname='best_advanced_model'),\n    ]\n    \n    # Create learner with advanced configuration\n    learner = cnn_learner(\n        dataloaders,\n        architecture,\n        pretrained=True,\n        metrics=[accuracy, error_rate, BalancedAccuracy()],\n        loss_func=loss_func,\n        cbs=callbacks\n    )\n    \n    # Apply advanced techniques\n    learner.model_dir = Path(OUTPUT_DIR)\n    \n    print(f\"\\nAdvanced Model Configuration:\")\n    print(f\"Architecture: {architecture.__name__}\")\n    print(f\"Loss Function: Focal Loss (α=1, γ=2) + Class Weights\")\n    print(f\"Regularization: MixUp (α=0.4) + CutMix (α=1.0)\")\n    print(f\"Metrics: Accuracy, Error Rate, Balanced Accuracy\")\n    print(f\"Callbacks: Early Stopping, LR Reduction, Model Saving\")\n    \n    return learner\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T17:59:28.682732Z\",\"iopub.execute_input\":\"2025-05-27T17:59:28.682980Z\",\"iopub.status.idle\":\"2025-05-27T17:59:28.706501Z\",\"shell.execute_reply.started\":\"2025-05-27T17:59:28.682935Z\",\"shell.execute_reply\":\"2025-05-27T17:59:28.705826Z\"}}\nclass BalancedAccuracy(Metric):\n    \"\"\"Custom metric for balanced accuracy using sklearn's `balanced_accuracy_score`.\"\"\"\n    \n    def __init__(self):\n        # You can optionally define a custom name via property\n        self._name = \"balanced_accuracy\"\n\n    @property\n    def name(self):\n        return self._name\n    \n    def reset(self):\n        # Initialize lists to accumulate predictions and targets\n        self.preds, self.targs = [], []\n    \n    def accumulate(self, learn):\n        # Collect predictions and true targets from the learner\n        preds = learn.pred.argmax(dim=-1)\n        targs = learn.y\n        self.preds.append(preds.detach().cpu())\n        self.targs.append(targs.detach().cpu())\n    \n    @property\n    def value(self):\n        # Compute the balanced accuracy from accumulated data\n        if not self.preds: return None\n        preds = torch.cat(self.preds)\n        targs = torch.cat(self.targs)\n        return balanced_accuracy_score(targs.numpy(), preds.numpy())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:37.469614Z\",\"iopub.execute_input\":\"2025-05-27T18:00:37.470170Z\",\"iopub.status.idle\":\"2025-05-27T18:00:37.479362Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:37.470145Z\",\"shell.execute_reply\":\"2025-05-27T18:00:37.478660Z\"}}\ndef progressive_training(learner, epochs: int = EPOCHS):\n    \"\"\"\n    Implement progressive training with multiple phases on a FastAI Learner.\n\n    Args:\n        learner (fastai.learner.Learner): The FastAI Learner instance.\n        epochs (int): Total number of training epochs.\n\n    Returns:\n        learner (fastai.learner.Learner): The trained learner.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from fastai.callback.schedule import lr_find\n    \n    # Verify the input type is a FastAI Learner\n    from fastai.learner import Learner\n    if not isinstance(learner, Learner):\n        raise TypeError(f\"Expected a FastAI Learner, but got {type(learner)}. \"\n                        \"Please pass the Learner, not the raw model.\")\n\n    logger.info(\"Starting progressive training...\")\n\n    # Find optimal learning rate\n    print(\"🔍 Finding optimal learning rate...\")\n    lr_suggestion = learner.lr_find()\n    learner.recorder.plot_lr_find()\n    plt.title('Learning Rate Finder', fontsize=14, fontweight='bold')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(f'{OUTPUT_DIR}/lr_finder.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    # Select learning rate with fallback\n    suggested_lr = lr_suggestion.valley if lr_suggestion.valley else 1e-3\n    if not (1e-6 <= suggested_lr <= 1e-1):\n        suggested_lr = 1e-3\n\n    print(f\"Selected Learning Rate: {suggested_lr:.2e}\")\n\n    # Phase 1: Train classifier head (freeze backbone)\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 1: Training Classifier Head (Frozen Backbone)\")\n    print(\"=\"*60)\n\n    epochs_phase1 = max(6, epochs // 4)\n    print(f\"Training for {epochs_phase1} epochs...\")\n\n    learner.freeze()\n    learner.fit_one_cycle(epochs_phase1, lr_max=suggested_lr)\n\n    print(\"Phase 1 completed! ✅\")\n\n    # Phase 2: Unfreeze and train with discriminative learning rates\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 2: Fine-tuning with Discriminative Learning Rates\")\n    print(\"=\"*60)\n\n    learner.unfreeze()\n    epochs_phase2 = max(8, epochs // 3)\n\n    lr_max = suggested_lr / 2\n    lr_schedule = slice(lr_max / 100, lr_max)\n\n    print(f\"Fine-tuning for {epochs_phase2} epochs...\")\n    print(f\"Learning rate schedule: {lr_max/100:.2e} to {lr_max:.2e}\")\n\n    learner.fit_one_cycle(epochs_phase2, lr_max=lr_schedule)\n\n    print(\"Phase 2 completed! ✅\")\n\n    # Phase 3: Final fine-tuning with ultra-low learning rate\n    print(\"\\n\" + \"=\"*60)\n    print(\"PHASE 3: Final Fine-tuning (Ultra-low Learning Rate)\")\n    print(\"=\"*60)\n\n    epochs_phase3 = epochs - epochs_phase1 - epochs_phase2\n    if epochs_phase3 > 0:\n        lr_final = suggested_lr / 20\n        print(f\"Final tuning for {epochs_phase3} epochs at LR: {lr_final:.2e}\")\n\n        learner.fit_one_cycle(epochs_phase3, lr_max=lr_final)\n        print(\"Phase 3 completed! ✅\")\n    else:\n        print(\"No Phase 3 epochs allocated, skipping final fine-tuning.\")\n\n    print(\"\\n🎉 Progressive training completed successfully!\")\n\n    \n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:42.628283Z\",\"iopub.execute_input\":\"2025-05-27T18:00:42.628549Z\",\"iopub.status.idle\":\"2025-05-27T18:00:42.639861Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:42.628529Z\",\"shell.execute_reply\":\"2025-05-27T18:00:42.638858Z\"}}\ndef comprehensive_evaluation(learner, df_test: pd.DataFrame, dataset_path: str) -> Dict[str, Any]:\n    \"\"\"Comprehensive model evaluation with advanced techniques.\"\"\"\n    logger.info(\"Performing comprehensive evaluation...\")\n    \n    # Filter valid test images\n    df_test_valid = df_test[\n        df_test['Path'].apply(lambda x: (Path(dataset_path) / x).exists())\n    ].reset_index(drop=True)\n    \n    if df_test_valid.empty:\n        raise ValueError(\"No valid test images found\")\n    \n    print(f\"Evaluating on {len(df_test_valid)} test images...\")\n    \n    # Create test DataLoader without augmentation\n    test_dls = ImageDataLoaders.from_df(\n        df_test_valid,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.0,\n        seed=SEED,\n        item_tfms=Resize(IMG_SIZE, method='squish'),\n        batch_tfms=None,\n        bs=32\n    )\n    \n    # Multi-method prediction ensemble\n    print(\"🔮 Generating predictions with ensemble methods...\")\n    \n    # Method 1: Test Time Augmentation (TTA)\n    preds_tta, y_true = learner.tta(dl=test_dls.train, n=8)\n    \n    # Method 2: Standard prediction\n    preds_std, _ = learner.get_preds(dl=test_dls.train)\n    \n    # Method 3: Progressive resize prediction\n    # Temporarily resize and predict\n    test_dls_large = ImageDataLoaders.from_df(\n        df_test_valid,\n        path=dataset_path,\n        fn_col='Path',\n        label_col='Class',\n        valid_pct=0.0,\n        seed=SEED,\n        item_tfms=Resize(288, method='squish'),  # Larger size\n        batch_tfms=None,\n        bs=16\n    )\n    \n    preds_large, _ = learner.get_preds(dl=test_dls_large.train)\n    \n    # Ensemble predictions (weighted average)\n    ensemble_preds = (preds_tta * 0.5 + preds_std * 0.3 + preds_large * 0.2)\n    pred_labels = ensemble_preds.argmax(dim=1)\n     \n    # Calculate comprehensive metrics\n    classes = learner.dls.vocab\n    label2idx = {label: i for i, label in enumerate(classes)}\n    true_labels = df_test_valid['Class'].map(label2idx).values\n    \n    # Primary metrics\n    accuracy = (pred_labels == tensor(true_labels)).float().mean().item()\n    balanced_acc = balanced_accuracy_score(true_labels, pred_labels)\n    \n    # Detailed classification report\n    class_report = classification_report(\n        true_labels, pred_labels,\n        target_names=classes,\n        output_dict=True\n    )\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, pred_labels)\n    \n    # Print detailed results\n    print(f\"\\n{'='*80}\")\n    print(\"COMPREHENSIVE EVALUATION RESULTS\")\n    print('='*80)\n    print(classification_report(true_labels, pred_labels, target_names=classes))\n    \n    # Per-class analysis\n    print(f\"\\nDETAILED PER-CLASS ANALYSIS:\")\n    print(\"-\" * 60)\n    for i, class_name in enumerate(classes):\n        if class_name in class_report:\n            metrics = class_report[class_name]\n            support = int(metrics['support'])\n            precision = metrics['precision']\n            recall = metrics['recall']\n            f1 = metrics['f1-score']\n            \n            print(f\"{class_name:15s}: P={precision:.3f} R={recall:.3f} F1={f1:.3f} (n={support})\")\n    \n    # Summary metrics\n    print(f\"\\n{'='*50}\")\n    print(\"SUMMARY METRICS\")\n    print('='*50)\n    print(f\"🎯 Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"⚖️  Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\n    print(f\"📊 Test Samples: {len(df_test_valid)}\")\n    print(f\"🎪 Ensemble Methods Used: TTA + Standard + Progressive Resize\")\n    \n    # Compile results\n    results = {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'classification_report': class_report,\n        'confusion_matrix': cm,\n        'test_samples': len(df_test_valid),\n        'classes': classes,\n        'ensemble_predictions': ensemble_preds,\n        'true_labels': true_labels,\n        'predicted_labels': pred_labels.numpy()\n    }\n    \n    return results\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:45.797238Z\",\"iopub.execute_input\":\"2025-05-27T18:00:45.797869Z\",\"iopub.status.idle\":\"2025-05-27T18:00:45.810518Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:45.797838Z\",\"shell.execute_reply\":\"2025-05-27T18:00:45.809810Z\"}}\ndef plot_advanced_confusion_matrix(cm: np.ndarray, classes: list, output_dir: str = OUTPUT_DIR):\n    \"\"\"Create advanced confusion matrix visualization.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n    \n    # 1. Raw confusion matrix\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes,\n                cmap='Blues', ax=axes[0,0], cbar_kws={'label': 'Count'})\n    axes[0,0].set_title('Confusion Matrix (Raw Counts)', fontsize=14, fontweight='bold')\n    axes[0,0].set_xlabel('Predicted Label', fontweight='bold')\n    axes[0,0].set_ylabel('True Label', fontweight='bold')\n    \n    # 2. Normalized confusion matrix\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    sns.heatmap(cm_norm, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes,\n                cmap='Reds', ax=axes[0,1], cbar_kws={'label': 'Recall Rate'})\n    axes[0,1].set_title('Confusion Matrix (Normalized by True Class)', fontsize=14, fontweight='bold')\n    axes[0,1].set_xlabel('Predicted Label', fontweight='bold')\n    axes[0,1].set_ylabel('True Label', fontweight='bold')\n    \n    # 3. Precision-focused normalization\n    cm_prec = cm.astype('float') / cm.sum(axis=0)\n    sns.heatmap(cm_prec, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes,\n                cmap='Greens', ax=axes[1,0], cbar_kws={'label': 'Precision Rate'})\n    axes[1,0].set_title('Confusion Matrix (Normalized by Predicted Class)', fontsize=14, fontweight='bold')\n    axes[1,0].set_xlabel('Predicted Label', fontweight='bold')\n    axes[1,0].set_ylabel('True Label', fontweight='bold')\n    \n    # 4. Error analysis\n    errors = cm - np.diag(np.diag(cm))  # Remove diagonal (correct predictions)\n    sns.heatmap(errors, annot=True, fmt='d', xticklabels=classes, yticklabels=classes,\n                cmap='OrRd', ax=axes[1,1], cbar_kws={'label': 'Error Count'})\n    axes[1,1].set_title('Error Analysis (Misclassifications Only)', fontsize=14, fontweight='bold')\n    axes[1,1].set_xlabel('Predicted Label', fontweight='bold')\n    axes[1,1].set_ylabel('True Label', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/advanced_confusion_matrix.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:52.245165Z\",\"iopub.execute_input\":\"2025-05-27T18:00:52.245435Z\",\"iopub.status.idle\":\"2025-05-27T18:00:52.251829Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:52.245415Z\",\"shell.execute_reply\":\"2025-05-27T18:00:52.251138Z\"}}\ndef save_advanced_model(learner, results: Dict, filename: str = 'advanced_wound_classifier.pkl'):\n    \"\"\"Save model with comprehensive metadata.\"\"\"\n    model_path = f'{OUTPUT_DIR}/{filename}'\n    learner.export(model_path)\n    \n    # Comprehensive metadata\n    metadata = {\n        'model_info': {\n            'architecture': 'resnet50',\n            'image_size': IMG_SIZE,\n            'batch_size': BATCH_SIZE,\n            'epochs_trained': EPOCHS,\n            'training_phases': 3,\n            'loss_function': 'Focal Loss + Class Weights',\n            'regularization': ['MixUp', 'CutMix', 'Heavy Augmentation'],\n        },\n        'performance': {\n            'test_accuracy': float(results['accuracy']),\n            'balanced_accuracy': float(results['balanced_accuracy']),\n            'test_samples': results['test_samples'],\n        },\n        'class_info': {\n            'classes': results['classes'],\n            'num_classes': len(results['classes']),\n        },\n        'techniques_used': [\n            'Synthetic Data Generation',\n            'Class Balancing',\n            'Progressive Training',\n            'Ensemble Predictions',\n            'Test Time Augmentation',\n            'Focal Loss',\n            'Advanced Callbacks',\n        ],\n        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'improvements': {\n            'class_imbalance': 'Addressed with synthetic data + class weights',\n            'overfitting': 'Prevented with regularization + callbacks',\n            'generalization': 'Enhanced with ensemble methods + TTA',\n        }\n    }\n    \n    # Save metadata\n    with open(f'{OUTPUT_DIR}/advanced_model_metadata.json', 'w') as f:\n        json.dump(metadata, f, indent=2, default=str)\n    \n    print(f\"✅ Advanced model saved successfully!\")\n    print(f\"📁 Model file: {model_path}\")\n    print(f\"📄 Metadata: {OUTPUT_DIR}/advanced_model_metadata.json\")\n    \n    return model_path\n\n# %% [code]\n# Install Google Drive API libraries if not already\n!pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nimport os\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\n# Path to your Kaggle-uploaded service account JSON key\nSERVICE_ACCOUNT_FILE = '/kaggle/input/json-key/our-velocity-460004-b1-5b54e5408593.json'\n\n# Your Google Drive folder ID (change as needed)\nFOLDER_ID = '13-eQTEydHlqPCucb70iOMZ1jCY5L32M-'  # (from your link above)\n\n# List all files you want to upload (absolute file paths and display names)\nfiles_to_upload = [\n    ('/kaggle/working/best_advanced_model.pth', 'best_advanced_model.pth'),\n    # add other files if needed\n]\n\n# Authenticate and create the service\ncredentials = service_account.Credentials.from_service_account_file(\n    SERVICE_ACCOUNT_FILE,\n    scopes=['https://www.googleapis.com/auth/drive']\n)\nservice = build('drive', 'v3', credentials=credentials)\n\n# Upload loop\nfor local_path, drive_filename in files_to_upload:\n    if os.path.exists(local_path):\n        file_metadata = {'name': drive_filename, 'parents': [FOLDER_ID]}\n        media = MediaFileUpload(local_path, resumable=True)\n        uploaded_file = service.files().create(\n            body=file_metadata, media_body=media, fields='id'\n        ).execute()\n        print(f\"✅ Uploaded {drive_filename} to Google Drive (File ID: {uploaded_file.get('id')})\")\n    else:\n        print(f\"❌ File not found: {local_path}\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:00:54.359340Z\",\"iopub.execute_input\":\"2025-05-27T18:00:54.359592Z\",\"iopub.status.idle\":\"2025-05-27T18:16:12.951319Z\",\"shell.execute_reply.started\":\"2025-05-27T18:00:54.359574Z\",\"shell.execute_reply\":\"2025-05-27T18:16:12.950334Z\"}}\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    print(\"🚀 Starting Advanced Wound Classification Pipeline\")\n    print(\"=\"*80)\n    \n    try:\n        # Step 1: Load and explore data\n        print(\"\\n📊 STEP 1: Loading and exploring dataset...\")\n        df = load_and_explore_data(DATASET_PATH)\n        \n        # Step 2: Create synthetic samples for class balancing\n        print(\"\\n🎨 STEP 2: Creating synthetic samples for class balancing...\")\n        balanced_df = create_synthetic_samples(df, DATASET_PATH, MIN_SAMPLES_PER_CLASS)\n        \n        # Step 3: Split data for training and testing\n        print(\"\\n🔄 STEP 3: Splitting data for training and testing...\")\n        train_df, test_df = train_test_split(\n            balanced_df, \n            test_size=0.15, \n            stratify=balanced_df['Class'], \n            random_state=SEED\n        )\n        \n        print(f\"Training samples: {len(train_df)}\")\n        print(f\"Testing samples: {len(test_df)}\")\n        print(f\"Training class distribution:\")\n        print(train_df['Class'].value_counts())\n        \n        # Step 4: Create advanced dataloaders\n        print(\"\\n🔧 STEP 4: Creating advanced dataloaders...\")\n        dataloaders = create_advanced_dataloaders(\n            train_df, \n            DATASET_PATH, \n            batch_size=BATCH_SIZE, \n            img_size=IMG_SIZE, \n            seed=SEED\n        )\n        \n        # Show sample batch\n        print(\"\\n📸 Displaying sample training batch...\")\n        dataloaders.show_batch(max_n=8, figsize=(12, 8))\n        plt.suptitle('Sample Training Batch with Augmentations', fontsize=16, fontweight='bold')\n        plt.tight_layout()\n        plt.savefig(f'{OUTPUT_DIR}/sample_batch.png', dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        # Step 5: Create advanced model\n        print(\"\\n🤖 STEP 5: Creating advanced model...\")\n        learner = create_advanced_model(dataloaders, architecture=resnet50)\n        \n        # Step 6: Progressive training\n        print(\"\\n🏋️ STEP 6: Training model with progressive approach...\")\n        trained_learner = progressive_training(learner, epochs=EPOCHS)\n        \n        # Step 7: Comprehensive evaluation\n        print(\"\\n📈 STEP 7: Performing comprehensive evaluation...\")\n        results = comprehensive_evaluation(trained_learner, test_df, DATASET_PATH)\n        \n        # Step 8: Advanced visualizations\n        print(\"\\n📊 STEP 8: Creating advanced visualizations...\")\n        \n        # Plot confusion matrices\n        plot_advanced_confusion_matrix(\n            results['confusion_matrix'], \n            results['classes'], \n            OUTPUT_DIR\n        )\n        \n        # Plot class distribution comparison\n        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n        \n        # Original distribution\n        original_counts = df['Class'].value_counts()\n        axes[0].bar(range(len(original_counts)), original_counts.values)\n        axes[0].set_title('Original Class Distribution', fontweight='bold')\n        axes[0].set_xticks(range(len(original_counts)))\n        axes[0].set_xticklabels(original_counts.index, rotation=45)\n        axes[0].set_ylabel('Count')\n        \n        # Balanced distribution\n        balanced_counts = balanced_df['Class'].value_counts()\n        axes[1].bar(range(len(balanced_counts)), balanced_counts.values, color='orange')\n        axes[1].set_title('Balanced Class Distribution', fontweight='bold')\n        axes[1].set_xticks(range(len(balanced_counts)))\n        axes[1].set_xticklabels(balanced_counts.index, rotation=45)\n        axes[1].set_ylabel('Count')\n        \n        # Performance by class\n        class_report = results['classification_report']\n        f1_scores = [class_report[cls]['f1-score'] for cls in results['classes'] if cls in class_report]\n        axes[2].bar(range(len(f1_scores)), f1_scores, color='green')\n        axes[2].set_title('F1-Score by Class', fontweight='bold')\n        axes[2].set_xticks(range(len(results['classes'])))\n        axes[2].set_xticklabels(results['classes'], rotation=45)\n        axes[2].set_ylabel('F1-Score')\n        axes[2].set_ylim(0, 1)\n        \n        # Add horizontal line at 0.8 for reference\n        axes[2].axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Good Performance (0.8)')\n        axes[2].legend()\n        \n        plt.tight_layout()\n        plt.savefig(f'{OUTPUT_DIR}/class_analysis.png', dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        # Step 9: Save model and results\n        print(\"\\n💾 STEP 9: Saving model and results...\")\n        model_path = save_advanced_model(trained_learner, results)\n        \n        # Save detailed results\n        results_summary = {\n            'dataset_info': {\n                'total_images': len(df),\n                'balanced_images': len(balanced_df),\n                'synthetic_images': len(balanced_df) - len(df),\n                'training_images': len(train_df),\n                'test_images': len(test_df),\n                'classes': results['classes'],\n                'class_counts': df['Class'].value_counts().to_dict()\n            },\n            'model_performance': {\n                'test_accuracy': float(results['accuracy']),\n                'balanced_accuracy': float(results['balanced_accuracy']),\n                'per_class_metrics': {\n                    cls: {\n                        'precision': float(results['classification_report'][cls]['precision']),\n                        'recall': float(results['classification_report'][cls]['recall']),\n                        'f1_score': float(results['classification_report'][cls]['f1-score']),\n                        'support': int(results['classification_report'][cls]['support'])\n                    }\n                    for cls in results['classes'] \n                    if cls in results['classification_report']\n                }\n            },\n            'improvements_implemented': [\n                \"✅ Class imbalance addressed with synthetic data generation\",\n                \"✅ Advanced augmentation techniques applied\",\n                \"✅ Focal loss with class weights for better minority class learning\",\n                \"✅ Progressive training with multiple phases\",\n                \"✅ Ensemble predictions with TTA\",\n                \"✅ Comprehensive evaluation metrics\",\n                \"✅ Advanced regularization (MixUp, CutMix, Cutout)\",\n                \"✅ Intelligent callbacks (Early Stopping, LR Scheduling)\"\n            ]\n        }\n        \n        with open(f'{OUTPUT_DIR}/comprehensive_results.json', 'w') as f:\n            json.dump(results_summary, f, indent=2, default=str)\n        \n        # Final summary\n        print(\"\\n\" + \"=\"*80)\n        print(\"🎉 ADVANCED WOUND CLASSIFICATION PIPELINE COMPLETED SUCCESSFULLY!\")\n        print(\"=\"*80)\n        print(f\"📊 Final Results Summary:\")\n        print(f\"   • Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n        print(f\"   • Balanced Accuracy: {results['balanced_accuracy']:.4f} ({results['balanced_accuracy']*100:.2f}%)\")\n        print(f\"   • Classes Handled: {len(results['classes'])}\")\n        print(f\"   • Total Test Samples: {results['test_samples']}\")\n        print(f\"   • Synthetic Samples Created: {len(balanced_df) - len(df)}\")\n        print(f\"\\n📁 Output Files:\")\n        print(f\"   • Model: {model_path}\")\n        print(f\"   • Metadata: {OUTPUT_DIR}/advanced_model_metadata.json\")\n        print(f\"   • Results: {OUTPUT_DIR}/comprehensive_results.json\")\n        print(f\"   • Visualizations: {OUTPUT_DIR}/*.png\")\n        \n        # Performance insights\n        avg_f1 = np.mean([results['classification_report'][cls]['f1-score'] \n                         for cls in results['classes'] if cls in results['classification_report']])\n        \n        print(f\"\\n🎯 Performance Insights:\")\n        print(f\"   • Average F1-Score: {avg_f1:.4f}\")\n        \n        if results['balanced_accuracy'] > 0.85:\n            print(f\"   • 🌟 EXCELLENT: Balanced accuracy > 85%\")\n        elif results['balanced_accuracy'] > 0.75:\n            print(f\"   • ✅ GOOD: Balanced accuracy > 75%\")\n        elif results['balanced_accuracy'] > 0.65:\n            print(f\"   • ⚠️  FAIR: Balanced accuracy > 65% - consider more data/tuning\")\n        else:\n            print(f\"   • ❌ NEEDS IMPROVEMENT: Balanced accuracy < 65%\")\n        \n        print(f\"\\n💡 Advanced Techniques Successfully Applied:\")\n        for improvement in results_summary['improvements_implemented']:\n            print(f\"   {improvement}\")\n        \n        print(f\"\\n🚀 Model is ready for deployment!\")\n        print(\"=\"*80)\n        \n        return trained_learner, results\n        \n    except Exception as e:\n        logger.error(f\"Pipeline failed with error: {str(e)}\")\n        print(f\"\\n❌ Error occurred: {str(e)}\")\n        print(\"Please check the dataset path and ensure all dependencies are installed.\")\n        raise e\n\n# Execute the pipeline\nif __name__ == \"__main__\":\n    # Set up the environment\n    print(\"Setting up environment...\")\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    if torch.cuda.is_available():\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    \n    # Run the main pipeline\n    model, evaluation_results = main()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-27T18:56:28.879819Z\",\"iopub.execute_input\":\"2025-05-27T18:56:28.880475Z\",\"iopub.status.idle\":\"2025-05-27T18:56:34.255198Z\",\"shell.execute_reply.started\":\"2025-05-27T18:56:28.880442Z\",\"shell.execute_reply\":\"2025-05-27T18:56:34.254334Z\"}}\n# Install Google Drive API libraries if not already\n!pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nimport os\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\n# Path to your Kaggle-uploaded service account JSON key\nSERVICE_ACCOUNT_FILE = '/kaggle/input/json-key/our-velocity-460004-b1-5b54e5408593.json'\n\n# Your Google Drive folder ID (change as needed)\nFOLDER_ID = '13-eQTEydHlqPCucb70iOMZ1jCY5L32M-'  # (from your link above)\n\n# List all files you want to upload (absolute file paths and display names)\nfiles_to_upload = [\n    ('/kaggle/working/best_advanced_model.pth', 'best_advanced_model.pth'),\n    # add other files if needed\n]\n\n# Authenticate and create the service\ncredentials = service_account.Credentials.from_service_account_file(\n    SERVICE_ACCOUNT_FILE,\n    scopes=['https://www.googleapis.com/auth/drive']\n)\nservice = build('drive', 'v3', credentials=credentials)\n\n# Upload loop\nfor local_path, drive_filename in files_to_upload:\n    if os.path.exists(local_path):\n        file_metadata = {'name': drive_filename, 'parents': [FOLDER_ID]}\n        media = MediaFileUpload(local_path, resumable=True)\n        uploaded_file = service.files().create(\n            body=file_metadata, media_body=media, fields='id'\n        ).execute()\n        print(f\"✅ Uploaded {drive_filename} to Google Drive (File ID: {uploaded_file.get('id')})\")\n    else:\n        print(f\"❌ File not found: {local_path}\")\n","metadata":{"_uuid":"f3fe49d9-a4f5-4fd7-8d01-514c8735f931","_cell_guid":"44f3b08a-8cc1-43bc-85ef-d58999613dba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}